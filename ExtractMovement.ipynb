{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !! WARNING !! Before you continue... \n",
    "\n",
    "1. Make sure you've made a copy in your Drive (you can't save otherwise)\n",
    "2. Make sure you've changed your kernel type to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup your linux environment on Google Colab\n",
    "\n",
    "!sudo apt install python3.8-full python3-pip\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
    "!python --version\n",
    "\n",
    "!pip3 install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "\n",
    "!pip install openmim \n",
    "!mim install mmengine \n",
    "!pip install mmcv==2.1.0 -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.1/index.html\n",
    "!mim install \"mmdet==3.1.0\" --quiet\n",
    "\n",
    "!git clone https://github.com/open-mmlab/mmpose.git\n",
    "%cd mmpose\n",
    "!pip install -r requirements.txt\n",
    "!pip install -v -e .\n",
    "# \"-v\" means verbose, or \n",
    "\n",
    "!mim install \"mmpose>=1.1.0\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Check that your install is working\n",
    "\n",
    "!mim download mmpose --config td-hm_hrnet-w48_8xb32-210e_coco-256x192  --dest .\n",
    "\n",
    "!python demo/image_demo.py \\\n",
    "    tests/data/coco/000000000785.jpg \\\n",
    "    td-hm_hrnet-w48_8xb32-210e_coco-256x192.py \\\n",
    "    td-hm_hrnet-w48_8xb32-210e_coco-256x192-0e67c616_20220913.pth \\\n",
    "    --out-file vis_results.jpg \\\n",
    "    --draw-heatmap\n",
    "\n",
    "\n",
    "# show image \n",
    "from IPython.display import Image\n",
    "Image(\"vis_results.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/Users/melian/Documents/UPenn/MAIN2024EDU/Foundation_Models_Primer_MAIN2024EDU/./demo/inferencer_demo.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#@title Now let's try inference on a video\n",
    "\n",
    "video_file = \"./demo/resources/demo.mp4\"\n",
    "pred_out_dir = \"./demo/resources/pred_out\"\n",
    "gpu_id = 0\n",
    "\n",
    "!python ./demo/inferencer_demo.py {video_file} \\\n",
    "              --pose2d vitpose-h --pred-out-dir {pred_out_dir} \\\n",
    "              --vis-out-dir {vis_out_dir} --device cuda:{gpu_id} --skeleton-style openpose --radius 25 --thickness 20 --black-background"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
